{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hypothesis testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "TeBp6bUhYRF8",
        "outputId": "a4cf084a-991a-4eff-855e-0a06639a3fd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (3,4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  0        1               2          3       4  \\\n",
              "0              Date   Admin2  Province/State  Confirmed  Deaths   \n",
              "1        22-01-2020  Autauga         Alabama          0       0   \n",
              "2        23-01-2020  Autauga         Alabama          0       0   \n",
              "3        24-01-2020  Autauga         Alabama          0       0   \n",
              "4        25-01-2020  Autauga         Alabama          0       0   \n",
              "...             ...      ...             ...        ...     ...   \n",
              "1048571  22-10-2020  Lincoln       Minnesota        172       0   \n",
              "1048572  23-10-2020  Lincoln       Minnesota        176       0   \n",
              "1048573  24-10-2020  Lincoln       Minnesota        182       0   \n",
              "1048574  25-10-2020  Lincoln       Minnesota        182       0   \n",
              "1048575  26-10-2020  Lincoln       Minnesota        184       0   \n",
              "\n",
              "                      5  \n",
              "0        Country/Region  \n",
              "1                    US  \n",
              "2                    US  \n",
              "3                    US  \n",
              "4                    US  \n",
              "...                 ...  \n",
              "1048571              US  \n",
              "1048572              US  \n",
              "1048573              US  \n",
              "1048574              US  \n",
              "1048575              US  \n",
              "\n",
              "[1048576 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df77c216-16ae-4196-bee5-40ed09761358\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Date</td>\n",
              "      <td>Admin2</td>\n",
              "      <td>Province/State</td>\n",
              "      <td>Confirmed</td>\n",
              "      <td>Deaths</td>\n",
              "      <td>Country/Region</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22-01-2020</td>\n",
              "      <td>Autauga</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23-01-2020</td>\n",
              "      <td>Autauga</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24-01-2020</td>\n",
              "      <td>Autauga</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25-01-2020</td>\n",
              "      <td>Autauga</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048571</th>\n",
              "      <td>22-10-2020</td>\n",
              "      <td>Lincoln</td>\n",
              "      <td>Minnesota</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048572</th>\n",
              "      <td>23-10-2020</td>\n",
              "      <td>Lincoln</td>\n",
              "      <td>Minnesota</td>\n",
              "      <td>176</td>\n",
              "      <td>0</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048573</th>\n",
              "      <td>24-10-2020</td>\n",
              "      <td>Lincoln</td>\n",
              "      <td>Minnesota</td>\n",
              "      <td>182</td>\n",
              "      <td>0</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048574</th>\n",
              "      <td>25-10-2020</td>\n",
              "      <td>Lincoln</td>\n",
              "      <td>Minnesota</td>\n",
              "      <td>182</td>\n",
              "      <td>0</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048575</th>\n",
              "      <td>26-10-2020</td>\n",
              "      <td>Lincoln</td>\n",
              "      <td>Minnesota</td>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1048576 rows Ã— 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df77c216-16ae-4196-bee5-40ed09761358')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df77c216-16ae-4196-bee5-40ed09761358 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df77c216-16ae-4196-bee5-40ed09761358');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# pandas helps to read and manipulate .csv file\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# read .csv file\n",
        "df = pd.read_csv('us_simplified.csv', sep=',', header=None)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-1UylTGnk2UC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-tj0ZuJPk5n-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = df[np.logical_not(df[3].str.contains('0'))]\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU45pgcYhzQy",
        "outputId": "36583b75-fdbc-4295-a206-214835b8b6b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 0         1               2          3       4  \\\n",
            "0             Date    Admin2  Province/State  Confirmed  Deaths   \n",
            "63      24-03-2020   Autauga         Alabama          1       0   \n",
            "64      25-03-2020   Autauga         Alabama          5       0   \n",
            "65      26-03-2020   Autauga         Alabama          6       0   \n",
            "66      27-03-2020   Autauga         Alabama          6       0   \n",
            "...            ...       ...             ...        ...     ...   \n",
            "131064  20-05-2020  Poinsett        Arkansas         28       2   \n",
            "131066  22-05-2020  Poinsett        Arkansas         31       2   \n",
            "131067  23-05-2020  Poinsett        Arkansas         31       2   \n",
            "131068  24-05-2020  Poinsett        Arkansas         31       2   \n",
            "131071  27-05-2020  Poinsett        Arkansas         31       2   \n",
            "\n",
            "                     5  \n",
            "0       Country/Region  \n",
            "63                  US  \n",
            "64                  US  \n",
            "65                  US  \n",
            "66                  US  \n",
            "...                ...  \n",
            "131064              US  \n",
            "131066              US  \n",
            "131067              US  \n",
            "131068              US  \n",
            "131071              US  \n",
            "\n",
            "[83788 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('us_simplified.csv')\n",
        "data.drop('Country/Region', inplace=True, axis=1)\n",
        "# # print(\"\\nCSV Data after deleting the column 'year':\\n\")\n",
        "print(data)\n",
        "# import pandas\n",
        "\n",
        "# data = pd.read_csv('us_simplified.csv')\n",
        "# print(data)\n",
        "# # display(data.head())\n",
        "# data['Date'] = pd.to_datetime(data.Date, infer_datetime_format = True)\n",
        "# # display(data.head())\n",
        "# data.sort_values(by = 'Date', ascending = True, inplace = True)\n",
        "# # csv_file = pandas.read_csv('us_simplified.csv' # you can implement options as you want here)\n",
        "# # sorted_csv = csv_file.sort_values(by=['Province/State'])\n",
        "# # sorted_csv = csv_file.sort_values(by=['Province/State'])\n",
        "# # sortedlist = sorted(reader, key=lambda row: row[], reverse=True)\n",
        "# # display(data.head(10000))\n",
        "# print(\"New data\")\n",
        "# print(data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF9CpUwtk4PO",
        "outputId": "30ea93f7-b374-49c6-efb4-a30d1e3801fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Date   Admin2 Province/State  Confirmed  Deaths\n",
            "0        22-01-2020  Autauga        Alabama          0       0\n",
            "1        23-01-2020  Autauga        Alabama          0       0\n",
            "2        24-01-2020  Autauga        Alabama          0       0\n",
            "3        25-01-2020  Autauga        Alabama          0       0\n",
            "4        26-01-2020  Autauga        Alabama          0       0\n",
            "...             ...      ...            ...        ...     ...\n",
            "1048570  22-10-2020  Lincoln      Minnesota        172       0\n",
            "1048571  23-10-2020  Lincoln      Minnesota        176       0\n",
            "1048572  24-10-2020  Lincoln      Minnesota        182       0\n",
            "1048573  25-10-2020  Lincoln      Minnesota        182       0\n",
            "1048574  26-10-2020  Lincoln      Minnesota        184       0\n",
            "\n",
            "[1048575 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # Read in your .csv files as dataframes\n",
        "# # df is a common standard for naming a dataframe. You can\n",
        "# # name them something more descriptive as well.\n",
        "# # Using a descriptive name is helpful when you are dealing\n",
        "# # with multiple .csv files.\n",
        "# df = pd.read_csv(\"us_simplified.csv\")\n",
        "\n",
        "# # the .sort_values method returns a new dataframe, so make sure to\n",
        "# # assign this to a new variable.\n",
        "# sorted_df = df.sort_values(by=[\"Province/State\"],by=[\"Admin2\"], ascending=True)\n",
        "# data.sort_values([\"depth\", \"table\", \"carat\"], axis=0,\n",
        "#                  ascending=[False, True, False], inplace=True)\n",
        "# # Index=False is a flag that tells pandas not to write\n",
        "# # the index of each row to a new column. If you'd like\n",
        "# # your rows to be numbered explicitly, leave this as\n",
        "# # the default, True\n",
        "# sorted_df.to_csv('homes_sorted.csv', index=False)\n",
        "# sorted_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "ApAa11wEt3uf",
        "outputId": "7c5e288b-9743-477a-abfd-6f641d924085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-42-2b7d9440b6ae>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    sorted_df = df.sort_values(by=[\"Province/State\"],by=[\"Admin2\"], ascending=True)\u001b[0m\n\u001b[0m                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword argument repeated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing pandas package\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# making data frame from csv file\n",
        "data = pd.read_csv(\"us_simplified.csv\")\n",
        "\n",
        "data.drop('Country/Region', inplace=True, axis=1)\n",
        "\n",
        "# sorting data frame by multiple columns\n",
        "data['Date'] = pd.to_datetime(data.Date, infer_datetime_format = True)\n",
        "# # display(data.head())\n",
        "# data.sort_values(by = 'Date', ascending = True, inplace = True)\n",
        "data.sort_values([\"Date\"  , \"Province/State\", \"Admin2\" ], axis=0,\n",
        "\t\t\t\tascending=[True, True, True], inplace=True)\n",
        "\n",
        "# display\n",
        "print(data.head(900))\n",
        "# print(data)\n",
        "\n",
        "  # MERGING #\n",
        "# import csv\n",
        "# # header = ['Date', 'Province/State', 'Confirmed', 'Deaths']\n",
        "# # i = 0\n",
        "# # x = 0\n",
        "# # sc = data[0][2]\n",
        "# # while(i<2486448):\n",
        "#   # x = i\n",
        "#   # s = data[x][2]\n",
        "#   # if s == sc:\n",
        "#   #   data2[] data[x][3]\n",
        "# # df2 = pd.DataFrame(columns=['Admin2','Province/State','Confirmed','Deaths'])\n",
        "# # i = 0\n",
        "# # count = 0\n",
        "# # state = data[i][2]\n",
        "# # date = df[i][0]\n",
        "# # df2.loc[count, \"Date\"] = data.loc[i, \"Date\"]\n",
        "# # df2.loc[count, \"Province/State\"] = data.loc[i, \"Province/State\"]\n",
        "# # df2.loc[count, \"Confirmed\"] = data.loc[i, \"Confirmed\"]\n",
        "# # df2.loc[count, \"Deaths\"] = data.loc[i, \"Deaths\"]\n",
        "# # i = i+1\n",
        "\n",
        "# # # while df[i][0] == date:\n",
        "# # #         df2[count][3] = df2[count][3] + data[i][3]\n",
        "# # #         df2[count][4] = df2[count][4] + data[i][4]\n",
        "# # #         i = i + 1\n",
        "# # #       else:\n",
        "# # while i<len(df):\n",
        "# #     while data[i][2] == state and data[i][0] == date:\n",
        "# #       df2[count][3]= df2[count][3] + data[i][3]\n",
        "# #       df2[count][4]= df2[count][4] + data[i][4]\n",
        "# #       i = i + 1\n",
        "# #     else:\n",
        "# #       count = count + 1\n",
        "# #       date = data[i][0]\n",
        "# #       state = data[i][2]\n",
        "# #       df2.loc[count, \"Date\"] = data.loc[i, \"Date\"]\n",
        "# #       df2.loc[count, \"Province/State\"] = data.loc[i, \"Province/State\"]\n",
        "# #       df2.loc[count, \"Confirmed\"] = data.loc[i, \"Confirmed\"]\n",
        "# #       df2.loc[count, \"Deaths\"] = data.loc[i, \"Deaths\"]\n",
        "# #       i = i + 1\n",
        "# data['Deaths_on_day'] = abs(data['Deaths'].shift(1) - data['Deaths'])\n",
        "# # print(data.head(100).to_string())\n",
        "# data['Deaths_on_day'] = abs(data['Deaths'].shift(1) - data['Deaths'])\n",
        "# data['Confirmed_on_day'] = abs(data['Confirmed'].shift(1) - data['Confirmed'])\n",
        "# i = 744\n",
        "# while i < len(df):\n",
        "#     data.loc[i, \"Confirmed_on_day\"] = 0\n",
        "#     data.loc[i, \"Deaths_on_day\"] = 0\n",
        "#     i = i + 744\n",
        "# print(data.head(1000).to_string())\n",
        "\n",
        "\n",
        "# df2 = pd.DataFrame(columns=['Admin2','Province/State','Confirmed','Deaths'])\n",
        "# i = 0\n",
        "# count = 0\n",
        "# state = data.loc[i, \"Province/State\"]\n",
        "# date = data.loc[i, \"Date\"]\n",
        "# # print(\"state\")\n",
        "# # print(state)\n",
        "# df2.loc[count, \"Date\"] = data.loc[i, \"Date\"]\n",
        "# df2.loc[count, \"Province/State\"] = data.loc[i, \"Province/State\"]\n",
        "# df2.loc[count, \"Confirmed\"] = data.loc[i, \"Confirmed\"]\n",
        "# df2.loc[count, \"Deaths\"] = data.loc[i, \"Deaths\"]\n",
        "# i = i+1\n",
        "\n",
        "# # while df[i][0] == date:\n",
        "# #         df2[count][3] = df2[count][3] + data[i][3]\n",
        "# #         df2[count][4] = df2[count][4] + data[i][4]\n",
        "# #         i = i + 1\n",
        "# #       else:\n",
        "# while i<len(df):\n",
        "#     while data.loc[i, \"Province/State\"] == state and data.loc[i, \"Date\"] == date:\n",
        "#       df2.loc[count, \"Confirmed\"]= df2.loc[count, \"Confirmed\"] + data.loc[i, \"Confirmed\"]\n",
        "#       df2.loc[count, \"Deaths\"]= df2.loc[count, \"Deaths\"] + data.loc[i, \"Deaths\"]\n",
        "#       i = i + 1\n",
        "#     else:\n",
        "#       count = count + 1\n",
        "#       date = data.loc[i, \"Date\"]\n",
        "#       state = data.loc[i, \"Province/State\"]\n",
        "#       df2.loc[count, \"Date\"] = data.loc[i, \"Date\"]\n",
        "#       df2.loc[count, \"Province/State\"] = data.loc[i, \"Province/State\"]\n",
        "#       df2.loc[count, \"Confirmed\"] = data.loc[i, \"Confirmed\"]\n",
        "#       df2.loc[count, \"Deaths\"] = data.loc[i, \"Deaths\"]\n",
        "#       i = i + 1\n",
        "\n",
        "\n",
        "# df2\n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIdXE7Hqv-Rh",
        "outputId": "de4ae86d-df29-4d77-fd2e-717679713606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Date     Admin2 Province/State  Confirmed  Deaths\n",
            "0      2020-01-22    Autauga        Alabama          0       0\n",
            "744    2020-01-22    Baldwin        Alabama          0       0\n",
            "1488   2020-01-22    Barbour        Alabama          0       0\n",
            "2232   2020-01-22       Bibb        Alabama          0       0\n",
            "2976   2020-01-22     Blount        Alabama          0       0\n",
            "...           ...        ...            ...        ...     ...\n",
            "665880 2020-01-22    O'Brien           Iowa          0       0\n",
            "666624 2020-01-22    Osceola           Iowa          0       0\n",
            "667368 2020-01-22  Out of IA           Iowa          0       0\n",
            "668112 2020-01-22       Page           Iowa          0       0\n",
            "668856 2020-01-22  Palo Alto           Iowa          0       0\n",
            "\n",
            "[900 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4ql8ZsYgGXwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "\n",
        "# making data frame from csv file\n",
        "data = pd.read_csv(\"us_simplified.csv\")\n",
        "\n",
        "data.drop('Country/Region', inplace=True, axis=1)\n",
        "\n",
        "# data['Deaths_on_day'] = abs(data['Deaths'].shift(1) - data['Deaths'])\n",
        "# print(data.head(100).to_string())\n",
        "data['Deaths_on_day'] = abs(data['Deaths'].shift(1) - data['Deaths'])\n",
        "data['Confirmed_on_day'] = abs(data['Confirmed'].shift(1) - data['Confirmed'])\n",
        "i = 744\n",
        "while i < len(df):\n",
        "    data.loc[i, \"Confirmed_on_day\"] = 0\n",
        "    data.loc[i, \"Deaths_on_day\"] = 0\n",
        "    i = i + 744\n",
        "data.loc[0, 'Deaths_on_day'] = 0\n",
        "data.loc[0, 'Confirmed_on_day'] = 0\n",
        "\n",
        "# print(data.head(10).to_string())\n",
        "\n",
        "df2 = pd.DataFrame(columns=['Admin2','Province/State','Confirmed','Deaths'])\n",
        "i = 0\n",
        "count = 0\n",
        "state = data.loc[i, \"Province/State\"]\n",
        "date = data.loc[i, \"Date\"]\n",
        "# print(\"state\")\n",
        "# print(state)\n",
        "df2.loc[count, \"Date\"] = data.loc[i, \"Date\"]\n",
        "df2.loc[count, \"Province/State\"] = data.loc[i, \"Province/State\"]\n",
        "df2.loc[count, \"Confirmed\"] = data.loc[i, \"Confirmed\"]\n",
        "df2.loc[count, \"Deaths\"] = data.loc[i, \"Deaths\"]\n",
        "i = i+1\n",
        "\n",
        "# while df[i][0] == date:\n",
        "#         df2[count][3] = df2[count][3] + data[i][3]\n",
        "#         df2[count][4] = df2[count][4] + data[i][4]\n",
        "#         i = i + 1\n",
        "#       else:\n",
        "while i<len(df):\n",
        "    while data.loc[i, \"Province/State\"] == state and data.loc[i, \"Date\"] == date:\n",
        "      df2.loc[count, \"Confirmed\"]= df2.loc[count, \"Confirmed\"] + data.loc[i, \"Confirmed\"]\n",
        "      df2.loc[count, \"Deaths\"]= df2.loc[count, \"Deaths\"] + data.loc[i, \"Deaths\"]\n",
        "      i = i + 1\n",
        "    else:\n",
        "      count = count + 1\n",
        "      date = data.loc[i, \"Date\"]\n",
        "      state = data.loc[i, \"Province/State\"]\n",
        "      df2.loc[count, \"Date\"] = data.loc[i, \"Date\"]\n",
        "      df2.loc[count, \"Province/State\"] = data.loc[i, \"Province/State\"]\n",
        "      df2.loc[count, \"Confirmed\"] = data.loc[i, \"Confirmed\"]\n",
        "      df2.loc[count, \"Deaths\"] = data.loc[i, \"Deaths\"]\n",
        "      i = i + 1\n",
        "\n",
        "\n",
        "# df2\n",
        "print(df2.head(10).to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "k2R5oT_havDU",
        "outputId": "2f5be04b-bc09-4097-edf6-853b41ad8916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-021021c2c2a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Province/State\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m       \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m       \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Province/State\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Province/State\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Confirmed\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Confirmed\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1705\u001b[0m                     \u001b[0mreindexers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m                     new_obj = self.obj._reindex_with_indexers(\n\u001b[0;32m-> 1707\u001b[0;31m                         \u001b[0mreindexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1708\u001b[0m                     )\n\u001b[1;32m   1709\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   4887\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4888\u001b[0m                 \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4889\u001b[0;31m                 \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4890\u001b[0m             )\n\u001b[1;32m   4891\u001b[0m             \u001b[0;31m# If we've made a copy once, no need to make another one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice)\u001b[0m\n\u001b[1;32m    686\u001b[0m                     ),\n\u001b[1;32m    687\u001b[0m                 )\n\u001b[0;32m--> 688\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m             ]\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    686\u001b[0m                     ),\n\u001b[1;32m    687\u001b[0m                 )\n\u001b[0;32m--> 688\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m             ]\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         new_values = algos.take_nd(\n\u001b[0;32m-> 1145\u001b[0;31m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m         )\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/array_algos/take.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_take_nd_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/array_algos/take.py\u001b[0m in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tabulate\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "\n",
        "df = pd.read_csv('us_simplified.csv')\n",
        "# print(df.head(100))\n",
        "df = df.drop('Country/Region', 1)\n",
        "# print(df.head(100).to_string())\n",
        "# df['Deaths_on_day'] = abs(df['Deaths'].shift(1) - df['Deaths'])\n",
        "# print(df.head(100).to_string())\n",
        "df['Deaths_on_day'] = abs(df['Deaths'].shift(1) - df['Deaths'])\n",
        "df['Confirmed_on_day'] = abs(df['Confirmed'].shift(1) - df['Confirmed'])\n",
        "i = 744\n",
        "while i < len(df):\n",
        "    df.loc[i, \"Confirmed_on_day\"] = 0\n",
        "    df.loc[i, \"Deaths_on_day\"] = 0\n",
        "    i = i + 744\n",
        "# print(df.head(1000).to_string())\n",
        "# for i in range(1000):\n",
        "#     if df.loc[i+1, \"Confirmed\"] >= df.loc[i, \"Confirmed\"]:\n",
        "#         df.loc[i+1, \"Confirmed_on_day\"] = df.loc[i+1, \"Confirmed\"]-df.loc[i, \"Confirmed\"]     \n",
        "    \n",
        "# print(df.head(1000).to_string())\n",
        "# print(df.tail(5000).to_string())\n",
        "df = df[df.Admin2 != \"Unassigned\"]\n",
        "# df = df[df['Admin2'].notna()]\n",
        "# print(df.tail(5000).to_string())\n",
        "# df = df.reset_index(drop=True)\n",
        "# print(df.loc[48358, \"Admin2\"])\n",
        "# df2 = pd.DataFrame(columns=['Admin2','Province/State','Confirmed','Deaths'])\n",
        "# i = 743\n",
        "# count = 0\n",
        "# while i < len(df):\n",
        "#     df2.loc[count, \"Confirmed\"] = df.loc[i, \"Confirmed\"]\n",
        "# #     print(df.loc[i, \"Confirmed\"])\n",
        "#     df2.loc[count, \"Deaths\"] = df.loc[i, \"Deaths\"] \n",
        "# #     print(str(df.loc[i, \"Deaths\"]) + \" \" + str(i))\n",
        "#     df2.loc[count, \"Admin2\"] = df.loc[i, \"Admin2\"]\n",
        "#     df2.loc[count, \"Province/State\"] = df.loc[i, \"Province/State\"]\n",
        "#     i = i + 744\n",
        "#     count = count + 1\n",
        "df.set_index(['Date','Province/State'], inplace=True)\n",
        "# df\n",
        "# df['Deaths_on_day'] = abs(df['Deaths'].shift(1) - df['Deaths'])\n",
        "# df['Confirmed_on_day'] = abs(df['Confirmed'].shift(1) - df['Confirmed'])\n",
        "# i = 744\n",
        "# while i < len(df):\n",
        "#     df.loc[i, \"Confirmed_on_day\"] = 0\n",
        "#     df.loc[i, \"Deaths_on_day\"] = 0\n",
        "#     i = i + 744\n",
        "# df\n",
        "# df.set_index(['Date','Province/State'], inplace=True)\n",
        "# df\n",
        "df.sort_index(inplace=True)\n",
        "# df\n",
        "# df\n",
        "df = df[df['Admin2'].notna()]\n",
        "# df\n",
        "print(df.head(400).to_string())\n",
        "# print(df2.to_markdown())\n",
        "# x = []\n",
        "# y = []\n",
        "  \n",
        "# with open('df2','r') as csvfile:\n",
        "#     plots = csv.reader(csvfile, delimiter = ',')\n",
        "      \n",
        "#     for row in plots:\n",
        "#         x.append(row[0])\n",
        "#         y.append(int(row[2]))\n",
        "  \n",
        "# plt.bar(x, y, color = 'b', width = 0.72, label = \"Age\")\n",
        "# plt.xlabel('Cities')\n",
        "# plt.ylabel('Cases')\n",
        "# plt.title('Total Cases in different cities')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHz-AAgDk7Bv",
        "outputId": "2325479c-43a8-4163-ebef-05141e2d584a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                              Admin2  Confirmed  Deaths  Deaths_on_day  Confirmed_on_day\n",
            "Date       Province/State                                                                                               \n",
            "01-01-2021 Alabama                                           Autauga       4239      50            2.0              49.0\n",
            "           Alabama                                           Baldwin      13823     169            8.0             222.0\n",
            "           Alabama                                           Barbour       1517      33            1.0               3.0\n",
            "           Alabama                                              Bibb       1854      46            0.0              20.0\n",
            "           Alabama                                            Blount       4693      63            0.0              52.0\n",
            "           Alabama                                           Bullock        888      22            0.0              29.0\n",
            "           Alabama                                            Butler       1522      45            0.0              14.0\n",
            "           Alabama                                           Calhoun       9584     157            1.0              90.0\n",
            "           Alabama                                          Chambers       2366      63            0.0              25.0\n",
            "           Alabama                                          Cherokee       1429      22            0.0              15.0\n",
            "           Alabama                                           Chilton       3004      54            0.0              34.0\n",
            "           Alabama                                           Choctaw        491      22            0.0               1.0\n",
            "           Alabama                                            Clarke       2418      26            1.0              28.0\n",
            "           Alabama                                              Clay       1150      34            0.0               9.0\n",
            "           Alabama                                          Cleburne       1036      16            0.0              10.0\n",
            "           Alabama                                            Coffee       3643      38            0.0              49.0\n",
            "           Alabama                                           Colbert       4701      60            0.0              41.0\n",
            "           Alabama                                           Conecuh        839      17            0.0               2.0\n",
            "           Alabama                                             Coosa        519       7            0.0               2.0\n",
            "           Alabama                                         Covington       2931      40            0.0              18.0\n",
            "           Alabama                                          Crenshaw        960      36            0.0               6.0\n",
            "           Alabama                                           Cullman       7194      78            0.0             115.0\n",
            "           Alabama                                              Dale       3371      63            0.0              46.0\n",
            "           Alabama                                            Dallas       2821      43            0.0              52.0\n",
            "           Alabama                                            DeKalb       6978      62            1.0              78.0\n",
            "           Alabama                                            Elmore       6542      83            0.0             107.0\n",
            "           Alabama                                          Escambia       2682      34            0.0              21.0\n",
            "           Alabama                                            Etowah      10110      96            2.0              79.0\n",
            "           Alabama                                           Fayette       1441      19            0.0              11.0\n",
            "           Alabama                                          Franklin       3300      37            0.0              30.0\n",
            "           Alabama                                            Geneva       1691      20            0.0              14.0\n",
            "           Alabama                                            Greene        679      20            0.0               7.0\n",
            "           Alabama                                              Hale       1468      33            0.0              28.0\n",
            "           Alabama                                             Henry       1268       8            0.0              21.0\n",
            "           Alabama                                           Houston       7371      64            0.0              92.0\n",
            "           Alabama                                           Jackson       5183      34            0.0              86.0\n",
            "           Alabama                                         Jefferson      53058     719           22.0             719.0\n",
            "           Alabama                                             Lamar       1065      15            0.0               9.0\n",
            "           Alabama                                        Lauderdale       6566      70            0.0              88.0\n",
            "           Alabama                                          Lawrence       2082      43            1.0              38.0\n",
            "           Alabama                                               Lee      10450      75            0.0             130.0\n",
            "           Alabama                                         Limestone       6879      58            0.0              57.0\n",
            "           Alabama                                           Lowndes        951      32            0.0               6.0\n",
            "           Alabama                                             Macon       1009      30            0.0              10.0\n",
            "           Alabama                                           Madison      22590     179            1.0             393.0\n",
            "           Alabama                                           Marengo       1812      26            0.0              19.0\n",
            "           Alabama                                            Marion       2112      43            0.0              25.0\n",
            "           Alabama                                          Marshall       9271      86            0.0              82.0\n",
            "           Alabama                                            Mobile      26151     508            2.0             293.0\n",
            "           Alabama                                            Monroe       1226      11            0.0              11.0\n",
            "           Alabama                                        Montgomery      16240     276            0.0             124.0\n",
            "           Alabama                                            Morgan      10817      89            2.0             190.0\n",
            "           Alabama                                         Out of AL          0       0            0.0               0.0\n",
            "           Alabama                                             Perry        879      10            0.0              12.0\n",
            "           Alabama                                           Pickens       1756      26            0.0              22.0\n",
            "           Alabama                                              Pike       2029      23            0.0               6.0\n",
            "           Alabama                                          Randolph       1262      30            0.0              17.0\n",
            "           Alabama                                           Russell       2824       6            0.0              31.0\n",
            "           Alabama                                            Shelby      15877     103            0.0             209.0\n",
            "           Alabama                                         St. Clair       6577      73            0.0             110.0\n",
            "           Alabama                                            Sumter        857      24            0.0               8.0\n",
            "           Alabama                                         Talladega       5211      76            1.0              46.0\n",
            "           Alabama                                        Tallapoosa       2383      98            0.0              15.0\n",
            "           Alabama                                        Tuscaloosa      18745     218            0.0             277.0\n",
            "           Alabama                                            Walker       5296     138            0.0              37.0\n",
            "           Alabama                                        Washington       1199      24            0.0              15.0\n",
            "           Alabama                                            Wilcox        890      19            0.0               7.0\n",
            "           Alabama                                           Winston       1977      30            0.0               9.0\n",
            "           Alaska                                     Aleutians East         39       0            0.0               0.0\n",
            "           Alaska                                     Aleutians West        198       0            0.0               0.0\n",
            "           Alaska                                          Anchorage      22922     120            0.0               0.0\n",
            "           Alaska                                             Bethel       2428       9            0.0               0.0\n",
            "           Alaska                                        Bristol Bay          0       0            0.0               0.0\n",
            "           Alaska                Bristol Bay plus Lake and Peninsula        158       0            0.0               0.0\n",
            "           Alaska                                            Chugach        221       3            0.0               0.0\n",
            "           Alaska                                       Copper River        157       0            0.0               5.0\n",
            "           Alaska                                             Denali         60       0            0.0               0.0\n",
            "           Alaska                                         Dillingham        122       1            0.0               0.0\n",
            "           Alaska                               Fairbanks North Star       4929      19            0.0               0.0\n",
            "           Alaska                                             Haines         22       0            0.0               0.0\n",
            "           Alaska                                      Hoonah-Angoon          0       0            0.0               0.0\n",
            "           Alaska                                             Juneau       1050       5            0.0               0.0\n",
            "           Alaska                                    Kenai Peninsula       3627      17            0.0               0.0\n",
            "           Alaska                                  Ketchikan Gateway        240       0            0.0               0.0\n",
            "           Alaska                                      Kodiak Island        914       2            0.0               0.0\n",
            "           Alaska                                           Kusilvak        767       2            0.0               0.0\n",
            "           Alaska                                  Matanuska-Susitna       6381      16            0.0               0.0\n",
            "           Alaska                                               Nome        275       0            0.0               0.0\n",
            "           Alaska                                        North Slope        806       2            0.0               0.0\n",
            "           Alaska                                   Northwest Arctic        401       0            0.0               0.0\n",
            "           Alaska                                          Out of AK          0       0            0.0               0.0\n",
            "           Alaska                                         Petersburg         31       1            0.0               0.0\n",
            "           Alaska                              Prince of Wales-Hyder         72       1            0.0               0.0\n",
            "           Alaska                                              Sitka        270       0            0.0               0.0\n",
            "           Alaska                                            Skagway         17       0            0.0               0.0\n",
            "           Alaska                                Southeast Fairbanks        408       3            0.0               0.0\n",
            "           Alaska                                     Valdez-Cordova          0       0            0.0               0.0\n",
            "           Alaska                                           Wrangell         25       0            0.0               0.0\n",
            "           Alaska                                            Yakutat         52       1            0.0               0.0\n",
            "           Alaska                                      Yukon-Koyukuk        209       4            0.0               0.0\n",
            "           Arizona                                            Apache       7594     244            7.0             156.0\n",
            "           Arizona                                           Cochise       7585     136            6.0             105.0\n",
            "           Arizona                                          Coconino      11344     214            4.0             218.0\n",
            "           Arizona                                              Gila       4552     136            1.0              35.0\n",
            "           Arizona                                            Graham       3287      51            0.0              59.0\n",
            "           Arizona                                          Greenlee        403       4            0.0               3.0\n",
            "           Arizona                                            La Paz       1523      35            0.0              59.0\n",
            "           Arizona                                          Maricopa     325404    5196           86.0            6577.0\n",
            "           Arizona                                            Mohave      12892     349            5.0             319.0\n",
            "           Arizona                                            Navajo      11559     347            5.0             263.0\n",
            "           Arizona                                         Out of AZ          0       0            0.0               0.0\n",
            "           Arizona                                              Pima      70563    1082           18.0            1041.0\n",
            "           Arizona                                             Pinal      28137     372            5.0             488.0\n",
            "           Arizona                                        Santa Cruz       6082     101            3.0              80.0\n",
            "           Arizona                                           Yavapai      11530     221            3.0             211.0\n",
            "           Arizona                                              Yuma      27812     527            8.0             446.0\n",
            "           Arkansas                                         Arkansas       1324      31            1.0              10.0\n",
            "           Arkansas                                           Ashley       1291      21            0.0              18.0\n",
            "           Arkansas                                           Baxter       2114      71            0.0              49.0\n",
            "           Arkansas                                           Benton      18355     266            2.0             597.0\n",
            "           Arkansas                                            Boone       2593      68            0.0              22.0\n",
            "           Arkansas                                          Bradley        957      15            4.0              17.0\n",
            "           Arkansas                                          Calhoun        239       1            0.0               5.0\n",
            "           Arkansas                                          Carroll       2110      30            0.0              37.0\n",
            "           Arkansas                                           Chicot       1418      30            0.0               8.0\n",
            "           Arkansas                                            Clark       1388      21            0.0              17.0\n",
            "           Arkansas                                             Clay       1332      31            1.0              15.0\n",
            "           Arkansas                                         Cleburne       1286      38            0.0              50.0\n",
            "           Arkansas                                        Cleveland        577      19            2.0               6.0\n",
            "           Arkansas                                         Columbia       1591      43            2.0              24.0\n",
            "           Arkansas                                           Conway       1343      16            0.0              37.0\n",
            "           Arkansas                                        Craighead      10176     136            0.0              99.0\n",
            "           Arkansas                                         Crawford       4542      59            1.0              91.0\n",
            "           Arkansas                                       Crittenden       4360      74            1.0              41.0\n",
            "           Arkansas                                            Cross       1424      36            0.0              30.0\n",
            "           Arkansas                                           Dallas        490      11            0.0               8.0\n",
            "           Arkansas                                            Desha        967      11            0.0              14.0\n",
            "           Arkansas                                             Drew       1463      19            0.0              15.0\n",
            "           Arkansas                                         Faulkner       7817      94            2.0             199.0\n",
            "           Arkansas                                         Franklin       1111      25            0.0              23.0\n",
            "           Arkansas                                           Fulton        895      36            0.0              11.0\n",
            "           Arkansas                                          Garland       5898     154            1.0             116.0\n",
            "           Arkansas                                            Grant       1101      12            0.0              30.0\n",
            "           Arkansas                                           Greene       4463      52            1.0              32.0\n",
            "           Arkansas                                        Hempstead       1240      11            0.0              20.0\n",
            "           Arkansas                                       Hot Spring       3661      56            1.0              25.0\n",
            "           Arkansas                                           Howard       1113      18            0.0               7.0\n",
            "           Arkansas                                     Independence       2809      94            1.0              58.0\n",
            "           Arkansas                                            Izard       1334      13            0.0              36.0\n",
            "           Arkansas                                          Jackson       2831      22            0.0              10.0\n",
            "           Arkansas                                        Jefferson       6797     129            2.0              79.0\n",
            "           Arkansas                                          Johnson       1885      20            0.0              62.0\n",
            "           Arkansas                                        Lafayette        345       4            0.0               3.0\n",
            "           Arkansas                                         Lawrence       1587      35            0.0              13.0\n",
            "           Arkansas                                              Lee       1449      26            0.0              19.0\n",
            "           Arkansas                                          Lincoln       2828      24            0.0               8.0\n",
            "           Arkansas                                     Little River        827      39            1.0               6.0\n",
            "           Arkansas                                            Logan       1453      11            0.0              34.0\n",
            "           Arkansas                                           Lonoke       4235      81            2.0             102.0\n",
            "           Arkansas                                          Madison       1048      12            0.0              23.0\n",
            "           Arkansas                                           Marion        655      24            0.0              26.0\n",
            "           Arkansas                                           Miller       2783      25            0.0              34.0\n",
            "           Arkansas                                      Mississippi       4411      95            1.0              18.0\n",
            "           Arkansas                                           Monroe        486       7            0.0              11.0\n",
            "           Arkansas                                       Montgomery        508      18            0.0              16.0\n",
            "           Arkansas                                           Nevada        598      20            0.0               4.0\n",
            "           Arkansas                                           Newton        557      24            0.0               4.0\n",
            "           Arkansas                                         Ouachita       1393      29            2.0              23.0\n",
            "           Arkansas                                        Out of AR          0       0            0.0               0.0\n",
            "           Arkansas                                            Perry        446       5            0.0               8.0\n",
            "           Arkansas                                         Phillips       1272      25            0.0               8.0\n",
            "           Arkansas                                             Pike        701      10            0.0              16.0\n",
            "           Arkansas                                         Poinsett       2418      62            0.0              12.0\n",
            "           Arkansas                                             Polk       1275      42            0.0              20.0\n",
            "           Arkansas                                             Pope       5584      58            0.0             136.0\n",
            "           Arkansas                                          Prairie        554      16            0.0               9.0\n",
            "           Arkansas                                          Pulaski      25209     392            2.0             547.0\n",
            "           Arkansas                                         Randolph       1473      42            0.0              18.0\n",
            "           Arkansas                                           Saline       7751     105            1.0             188.0\n",
            "           Arkansas                                            Scott        611      11            0.0              23.0\n",
            "           Arkansas                                           Searcy        510      11            0.0               7.0\n",
            "           Arkansas                                        Sebastian       9788     158            2.0             274.0\n",
            "           Arkansas                                           Sevier       2096      20            0.0              17.0\n",
            "           Arkansas                                            Sharp       1158      32            0.0              24.0\n",
            "           Arkansas                                      St. Francis       2758      20            0.0              30.0\n",
            "           Arkansas                                            Stone        770      27            0.0               5.0\n",
            "           Arkansas                                            Union       2523      73            0.0              95.0\n",
            "           Arkansas                                        Van Buren        771       8            0.0              28.0\n",
            "           Arkansas                                       Washington      21805     223            1.0             385.0\n",
            "           Arkansas                                            White       4893      69            0.0             145.0\n",
            "           Arkansas                                         Woodruff        367       2            0.0               5.0\n",
            "           Arkansas                                             Yell       2423      43            1.0              33.0\n",
            "           California                                        Alameda      54643     579            0.0            1078.0\n",
            "           California                                         Alpine         67       0            0.0               0.0\n",
            "           California                                         Amador       2533      24            0.0              20.0\n",
            "           California                                          Butte       8584     105            0.0             203.0\n",
            "           California                                      Calaveras       1189      21            0.0              25.0\n",
            "           California                                         Colusa       1416       7            0.0              16.0\n",
            "           California                                   Contra Costa      42075     351           15.0             915.0\n",
            "           California                                      Del Norte        760       2            0.0              10.0\n",
            "           California                                      El Dorado       6182      27            1.0             179.0\n",
            "           California                                         Fresno      72692     717            6.0            1106.0\n",
            "           California                                          Glenn       1820       9            0.0              41.0\n",
            "           California                                       Humboldt       1789      21            0.0              70.0\n",
            "           California                                       Imperial      24338     418            1.0             237.0\n",
            "           California                                           Inyo        624      20            0.0              15.0\n",
            "           California                                           Kern      69484     512            0.0             515.0\n",
            "           California                                          Kings      16953     108            0.0             289.0\n",
            "           California                                           Lake       1888      24            1.0              40.0\n",
            "           California                                         Lassen       4691      10            0.0               0.0\n",
            "           California                                    Los Angeles     790582   10552          193.0           19063.0\n",
            "           California                                         Madera      11253      66            2.0             152.0\n",
            "           California                                          Marin       9916     148            0.0              92.0\n",
            "           California                                       Mariposa        255       4            0.0               3.0\n",
            "           California                                      Mendocino       2426      24            0.0              37.0\n",
            "           California                                         Merced      19512     229            3.0             320.0\n",
            "           California                                          Modoc        318       0            0.0               3.0\n",
            "           California                                           Mono        895       3            0.0              16.0\n",
            "           California                                       Monterey      29253     191            3.0             757.0\n",
            "           California                                           Napa       5925      28            0.0              98.0\n",
            "           California                                         Nevada       2759      15            0.0              46.0\n",
            "           California                                         Orange     183865    1875            0.0            1181.0\n",
            "           California                                      Out of CA          0       0            0.0               0.0\n",
            "           California                                         Placer      14645     133            7.0             282.0\n",
            "           California                                         Plumas        421       1            0.0              12.0\n",
            "           California                                      Riverside     198089    1990           32.0            4614.0\n",
            "           California                                     Sacramento      67654     848           18.0            1150.0\n",
            "           California                                     San Benito       3806      28            0.0             100.0\n",
            "           California                                 San Bernardino     209664    1590            4.0            4605.0\n",
            "           California                                      San Diego     168145    1592           58.0            4571.0\n",
            "           California                                  San Francisco      24393     187            4.0             413.0\n",
            "           California                                    San Joaquin      48460     657           11.0             914.0\n",
            "           California                                San Luis Obispo      11442      94            5.0             314.0\n",
            "           California                                      San Mateo      25173     194            2.0             477.0\n",
            "           California                                  Santa Barbara      18344     164            3.0             332.0\n",
            "           California                                    Santa Clara      72218     680           15.0            1878.0\n",
            "           California                                     Santa Cruz       9551      84            0.0             249.0\n",
            "           California                                         Shasta       8880      72            3.0             116.0\n",
            "           California                                         Sierra         33       0            0.0               0.0\n",
            "           California                                       Siskiyou       1073       3            0.0               7.0\n",
            "           California                                         Solano      19587      97            0.0             452.0\n",
            "           California                                         Sonoma      19627     189            1.0             385.0\n",
            "           California                                     Stanislaus      38503     553            1.0             633.0\n",
            "           California                                         Sutter       6602      52            1.0             121.0\n",
            "           California                                         Tehama       3408       9            0.0              44.0\n",
            "           California                                        Trinity        296       2            0.0               2.0\n",
            "           California                                         Tulare      38189     454            8.0             644.0\n",
            "           California                                       Tuolumne       2923      13            1.0               7.0\n",
            "           California                                        Ventura      43819     253            2.0            1189.0\n",
            "           California                                           Yolo       8535     120            3.0             167.0\n",
            "           California                                           Yuba       3885      19            1.0              47.0\n",
            "           Colorado                                            Adams      40304     521            3.0             387.0\n",
            "           Colorado                                          Alamosa        948      24            0.0              13.0\n",
            "           Colorado                                         Arapahoe      38334     562            5.0             373.0\n",
            "           Colorado                                        Archuleta        487       0            0.0               2.0\n",
            "           Colorado                                             Baca        194       1            0.0               5.0\n",
            "           Colorado                                             Bent       1126      12            0.0              89.0\n",
            "           Colorado                                          Boulder      14729     174            2.0             105.0\n",
            "           Colorado                                       Broomfield       2837      67            1.0              33.0\n",
            "           Colorado                                          Chaffee       1072      21            0.0              52.0\n",
            "           Colorado                                         Cheyenne         89       5            0.0               0.0\n",
            "           Colorado                                      Clear Creek        282       2            0.0               3.0\n",
            "           Colorado                                          Conejos        318       3            0.0               3.0\n",
            "           Colorado                                         Costilla        163       2            0.0               2.0\n",
            "           Colorado                                          Crowley       1660      12            0.0              13.0\n",
            "           Colorado                                           Custer        148       0            0.0               0.0\n",
            "           Colorado                                            Delta       1610      25            0.0              30.0\n",
            "           Colorado                                           Denver      48023     669            2.0             378.0\n",
            "           Colorado                                          Dolores         52       0            0.0               0.0\n",
            "           Colorado                                          Douglas      15783     195            0.0             137.0\n",
            "           Colorado                                            Eagle       3392      16            0.0              18.0\n",
            "           Colorado                                          El Paso      41556     567           12.0             334.0\n",
            "           Colorado                                           Elbert        996      10            1.0               9.0\n",
            "           Colorado                                          Fremont       4681      20            1.0              19.0\n",
            "           Colorado                                         Garfield       3916      29            1.0              41.0\n",
            "           Colorado                                           Gilpin        125       1            0.0               0.0\n",
            "           Colorado                                            Grand        671       4            0.0              11.0\n",
            "           Colorado                                         Gunnison        714       6            0.0              18.0\n",
            "           Colorado                                         Hinsdale         14       0            0.0               1.0\n",
            "           Colorado                                         Huerfano        276      18            0.0               0.0\n",
            "           Colorado                                          Jackson         33       0            0.0               0.0\n",
            "           Colorado                                        Jefferson      29776     617            5.0             211.0\n",
            "           Colorado                                            Kiowa         75       2            0.0               0.0\n",
            "           Colorado                                       Kit Carson        438       9            0.0               2.0\n",
            "           Colorado                                         La Plata       2245      28            0.0              19.0\n",
            "           Colorado                                             Lake        433       0            0.0               7.0\n",
            "           Colorado                                          Larimer      15232     147            5.0             133.0\n",
            "           Colorado                                       Las Animas        512       6            0.0               6.0\n",
            "           Colorado                                          Lincoln        783       3            0.0              12.0\n",
            "           Colorado                                            Logan       3249      55            1.0              11.0\n",
            "           Colorado                                             Mesa       9239     139            5.0             184.0\n",
            "           Colorado                                          Mineral         44       1            0.0               2.0\n",
            "           Colorado                                           Moffat        543      20            1.0               2.0\n",
            "           Colorado                                        Montezuma       1242      16            0.0              11.0\n",
            "           Colorado                                         Montrose       2134      31            0.0              20.0\n",
            "           Colorado                                           Morgan       2136      82            1.0              17.0\n",
            "           Colorado                                            Otero       1648      39            0.0              29.0\n",
            "           Colorado                                            Ouray        155       3            0.0               1.0\n",
            "           Colorado                                        Out of CO          0       0            0.0               0.0\n",
            "           Colorado                                             Park        384       5            0.0               1.0\n",
            "           Colorado                                         Phillips        286       8            1.0               8.0\n",
            "           Colorado                                           Pitkin       1045       4            0.0               2.0\n",
            "           Colorado                                          Prowers       1007      20            0.0               3.0\n",
            "           Colorado                                           Pueblo      13328     313            9.0             110.0\n",
            "           Colorado                                       Rio Blanco        269       3            0.0               2.0\n",
            "           Colorado                                       Rio Grande        393       7            0.0               9.0\n",
            "           Colorado                                            Routt       1058      18            0.0              16.0\n",
            "           Colorado                                         Saguache        256       4            0.0               1.0\n",
            "           Colorado                                         San Juan         27       0            0.0               0.0\n",
            "           Colorado                                       San Miguel        394       0            0.0               0.0\n",
            "           Colorado                                         Sedgwick        134       2            0.0               8.0\n",
            "           Colorado                                           Summit       2143       5            0.0               9.0\n",
            "           Colorado                                           Teller        994       9            0.0               4.0\n",
            "           Colorado                                       Washington        347      11            1.0               0.0\n",
            "           Colorado                                             Weld      20100     287            2.0             175.0\n",
            "           Colorado                                             Yuma        552      13            0.0               3.0\n",
            "           Connecticut                                     Fairfield      56288    1720            0.0               0.0\n",
            "           Connecticut                                      Hartford      46680    1852            0.0               0.0\n",
            "           Connecticut                                    Litchfield       7476     225            0.0               0.0\n",
            "           Connecticut                                     Middlesex       6566     237            0.0               0.0\n",
            "           Connecticut                                     New Haven      47375    1529            0.0               0.0\n",
            "           Connecticut                                    New London      10618     245            0.0               0.0\n",
            "           Connecticut                                     Out of CT          0       0            0.0               0.0\n",
            "           Connecticut                                       Tolland       4900     109            0.0               0.0\n",
            "           Connecticut                                       Windham       5140      78            0.0               0.0\n",
            "           Delaware                                             Kent       9329     200            3.0             156.0\n",
            "           Delaware                                       New Castle      33433     541            0.0             222.0\n",
            "           Delaware                                        Out of DE          0       0            0.0               0.0\n",
            "           Delaware                                           Sussex      15166     324            1.0             230.0\n",
            "           District of Columbia                 District of Columbia      29252     788            2.0             269.0\n",
            "           District of Columbia                            Out of DC          0       0            0.0               0.0\n",
            "           Florida                                           Alachua      15866     129            0.0               0.0\n",
            "           Florida                                             Baker       2470      36            0.0               0.0\n",
            "           Florida                                               Bay      11907     209            0.0               0.0\n",
            "           Florida                                          Bradford       2180      23            0.0               0.0\n",
            "           Florida                                           Brevard      21034     523            0.0               0.0\n",
            "           Florida                                           Broward     137610    1847            0.0               0.0\n",
            "           Florida                                           Calhoun       1233      28            0.0               0.0\n",
            "           Florida                                         Charlotte       7410     231            0.0               0.0\n",
            "           Florida                                            Citrus       6663     266            0.0               0.0\n",
            "           Florida                                              Clay      11261     186            0.0               0.0\n",
            "           Florida                                           Collier      22506     332            0.0               0.0\n",
            "           Florida                                          Columbia       6007     117            0.0               0.0\n",
            "           Florida                                            DeSoto       2898      56            0.0               0.0\n",
            "           Florida                                             Dixie       1115      11            0.0               0.0\n",
            "           Florida                                             Duval      61321     725            0.0               0.0\n",
            "           Florida                                          Escambia      22349     373            0.0               0.0\n",
            "           Florida                                           Flagler       3724      48            0.0               0.0\n",
            "           Florida                                          Franklin        900       4            0.0               0.0\n",
            "           Florida                                           Gadsden       3988      59            0.0               0.0\n",
            "           Florida                                         Gilchrist       1014      23            0.0               0.0\n",
            "           Florida                                            Glades        769      11            0.0               0.0\n",
            "           Florida                                              Gulf       1333      27            0.0               0.0\n",
            "           Florida                                          Hamilton       1277      15            0.0               0.0\n",
            "           Florida                                            Hardee       2110      20            0.0               0.0\n",
            "           Florida                                            Hendry       3291      49            0.0               0.0\n",
            "           Florida                                          Hernando       7336     278            0.0               0.0\n",
            "           Florida                                         Highlands       4975     204            0.0               0.0\n",
            "           Florida                                      Hillsborough      77118    1071            0.0               0.0\n",
            "           Florida                                            Holmes       1683      25            0.0               0.0\n",
            "           Florida                                      Indian River       6875     159            0.0               0.0\n",
            "           Florida                                           Jackson       4649     118            0.0               0.0\n",
            "           Florida                                         Jefferson        994      16            0.0               0.0\n",
            "           Florida                                         Lafayette       1422      22            0.0               0.0\n",
            "           Florida                                              Lake      15559     295            0.0               0.0\n",
            "           Florida                                               Lee      40635     672            0.0               0.0\n",
            "           Florida                                              Leon      19574     175            0.0               0.0\n",
            "           Florida                                              Levy       1851      19            0.0               0.0\n",
            "           Florida                                           Liberty        750      14            0.0               0.0\n",
            "           Florida                                           Madison       1540      33            0.0               0.0\n",
            "           Florida                                           Manatee      22332     433            0.0               0.0\n",
            "           Florida                                            Marion      17799     463            0.0               0.0\n",
            "           Florida                                            Martin       7839     210            0.0               0.0\n",
            "           Florida                                        Miami-Dade     298873    4188            0.0               0.0\n",
            "           Florida                                            Monroe       4226      35            0.0               0.0\n",
            "           Florida                                            Nassau       4775      66            0.0               0.0\n",
            "           Florida                                          Okaloosa      12857     231            0.0               0.0\n",
            "           Florida                                        Okeechobee       2430      51            0.0               0.0\n",
            "           Florida                                            Orange      76458     749            0.0               0.0\n",
            "           Florida                                           Osceola      25344     288            0.0               0.0\n",
            "           Florida                                         Out of FL          0       0            0.0               0.0\n",
            "           Florida                                        Palm Beach      82890    1895            0.0               0.0\n",
            "           Florida                                             Pasco      21932     376            0.0               0.0\n",
            "           Florida                                          Pinellas      44975    1049            0.0               0.0\n",
            "           Florida                                              Polk      37403     790            0.0               0.0\n",
            "           Florida                                            Putnam       3990      72            0.0               0.0\n",
            "           Florida                                        Santa Rosa      11180     128            0.0               0.0\n",
            "           Florida                                          Sarasota      18607     509            0.0               0.0\n",
            "           Florida                                          Seminole      18083     314            0.0               0.0\n",
            "           Florida                                         St. Johns      13072     113            0.0               0.0\n",
            "           Florida                                         St. Lucie      14278     405            0.0               0.0\n",
            "           Florida                                            Sumter       5085     120            0.0               0.0\n",
            "           Florida                                          Suwannee       4015      97            0.0               0.0\n",
            "           Florida                                            Taylor       1967      25            0.0               0.0\n",
            "           Florida                                             Union       1439      65            0.0               0.0\n",
            "           Florida                                           Volusia      22291     449            0.0               0.0\n",
            "           Florida                                           Wakulla       2106      25            0.0               0.0\n",
            "           Florida                                            Walton       4891      48            0.0               0.0\n",
            "           Florida                                        Washington       1971      30            0.0               0.0\n",
            "           Georgia                                           Appling       1688      44            0.0              21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing library\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "import math\n",
        "#reading the dataset\n",
        "cp = pd.read_csv('usa_final.csv')\n",
        "#taking the subset of the data\n",
        "# cp=cp[['symboling','wheelbase','carlength','carwidth','carheight','curbweight','boreratio','stroke','compressionratio','horsepower','peakrpm','citympg','highwaympg','price']]\n",
        "#printing first five rows of the data\n",
        "# cp.head()\n",
        "cp.skew()\n",
        "# sns.kdeplot(cp.Confirmed_on_day);\n",
        "# stats.probplot(cp.Confirmed_on_day,plot=pylab);\n",
        "def normality(usa_final,Confirmed_on_day):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    sns.kdeplot(usa_final[Confirmed_on_day])\n",
        "    plt.subplot(1,2,2)\n",
        "    stats.probplot(usa_final[Confirmed_on_day],plot=pylab)\n",
        "    # plt.show()\n",
        "# stats.probplot(cp.Confirmed_on_day,plot=pylab);\n",
        "# cp['Confirmed_on_day_log']=np.log(cp['Confirmed_on_day'])\n",
        "# normality(cp,'Confirmed_on_day_log')\n",
        "# cp['Confirmed_on_day_reciprocal']=1/cp.Confirmed_on_day\n",
        "# normality(cp,'Confirmed_on_day_reciprocal')\n",
        "cp['Confirmed_on_day_sqroot']=np.sqrt(cp.Confirmed_on_day)\n",
        "print('Confirmed_on_day_sqroot')\n",
        "# normality(cp,'Confirmed_on_day_sqroot')\n",
        "# cp['cod_us_new']=np.sqrt(cp.Confirmed_on_day)\n",
        "# cod = cp['cod_us_new']\n",
        "cp['Confirmed_on_day_sqroot'].mean()\n",
        "\n",
        "\n",
        "# cp['Confirmed_on_day_exponential']=cp.Confirmed_on_day**(1/1.2)\n",
        "# normality(cp,'Confirmed_on_day_exponential')\n",
        "# cp['Confirmed_on_day_Boxcox'],parameters=stats.boxcox(cp['Confirmed_on_day'])\n",
        "# normality(cp,'Deaths_on_day_Boxcox')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH2EUgNaBEWC",
        "outputId": "921912ae-015f-409d-9e8f-5dd52c9e89fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confirmed_on_day_sqroot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "277.1503705282212"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tabulate\n",
        "\n",
        "df = pd.read_csv('us_simplified.csv')\n",
        "print(df.head(100))\n",
        "df = df.drop('Country/Region', 1)\n",
        "print(df.head(20).to_string())\n",
        "df['Deaths_on_day'] = abs(df['Deaths'].shift(1) - df['Deaths'])\n",
        "df['Confirmed_on_day'] = abs(df['Confirmed'].shift(1) - df['Confirmed'])\n",
        "i = 744\n",
        "while i < len(df):\n",
        "    df.loc[i, \"Confirmed_on_day\"] = 0\n",
        "    df.loc[i, \"Deaths_on_day\"] = 0\n",
        "    i = i + 744\n",
        "# df\n",
        "df.set_index(['Date','Province/State'], inplace=True)\n",
        "# df\n",
        "df.sort_index(inplace=True)\n",
        "# df\n",
        "# df\n",
        "df = df[df['Admin2'].notna()]\n",
        "df.sort_values([\"Date\",\"Province/State\", \"Admin2\" ], axis=0,\n",
        "\t\t\t\tascending=[True, True, True], inplace=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J7gAsmBWFDMM",
        "outputId": "79492e71-a850-4749-f4ac-c0df491df0e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Date   Admin2 Province/State  Confirmed  Deaths Country/Region\n",
            "0   22-01-2020  Autauga        Alabama          0       0             US\n",
            "1   23-01-2020  Autauga        Alabama          0       0             US\n",
            "2   24-01-2020  Autauga        Alabama          0       0             US\n",
            "3   25-01-2020  Autauga        Alabama          0       0             US\n",
            "4   26-01-2020  Autauga        Alabama          0       0             US\n",
            "..         ...      ...            ...        ...     ...            ...\n",
            "95  26-04-2020  Autauga        Alabama         36       2             US\n",
            "96  27-04-2020  Autauga        Alabama         37       3             US\n",
            "97  28-04-2020  Autauga        Alabama         39       4             US\n",
            "98  29-04-2020  Autauga        Alabama         41       4             US\n",
            "99  30-04-2020  Autauga        Alabama         42       4             US\n",
            "\n",
            "[100 rows x 6 columns]\n",
            "          Date   Admin2 Province/State  Confirmed  Deaths\n",
            "0   22-01-2020  Autauga        Alabama          0       0\n",
            "1   23-01-2020  Autauga        Alabama          0       0\n",
            "2   24-01-2020  Autauga        Alabama          0       0\n",
            "3   25-01-2020  Autauga        Alabama          0       0\n",
            "4   26-01-2020  Autauga        Alabama          0       0\n",
            "5   27-01-2020  Autauga        Alabama          0       0\n",
            "6   28-01-2020  Autauga        Alabama          0       0\n",
            "7   29-01-2020  Autauga        Alabama          0       0\n",
            "8   30-01-2020  Autauga        Alabama          0       0\n",
            "9   31-01-2020  Autauga        Alabama          0       0\n",
            "10  01-02-2020  Autauga        Alabama          0       0\n",
            "11  02-02-2020  Autauga        Alabama          0       0\n",
            "12  03-02-2020  Autauga        Alabama          0       0\n",
            "13  04-02-2020  Autauga        Alabama          0       0\n",
            "14  05-02-2020  Autauga        Alabama          0       0\n",
            "15  06-02-2020  Autauga        Alabama          0       0\n",
            "16  07-02-2020  Autauga        Alabama          0       0\n",
            "17  08-02-2020  Autauga        Alabama          0       0\n",
            "18  09-02-2020  Autauga        Alabama          0       0\n",
            "19  10-02-2020  Autauga        Alabama          0       0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      Admin2  Confirmed  Deaths  \\\n",
              "Date       Province/State                                         \n",
              "01-01-2021 Alabama                   Autauga       4239      50   \n",
              "           Alabama                   Baldwin      13823     169   \n",
              "           Alabama                   Barbour       1517      33   \n",
              "           Alabama                      Bibb       1854      46   \n",
              "           Alabama                    Blount       4693      63   \n",
              "...                                      ...        ...     ...   \n",
              "31-12-2021 Minnesota             Koochiching       1996      29   \n",
              "           Minnesota           Lac qui Parle       1341      26   \n",
              "           Minnesota                    Lake       1475      26   \n",
              "           Minnesota       Lake of the Woods        566       5   \n",
              "           Minnesota                Le Sueur       5074      41   \n",
              "\n",
              "                           Deaths_on_day  Confirmed_on_day  \n",
              "Date       Province/State                                   \n",
              "01-01-2021 Alabama                   2.0              49.0  \n",
              "           Alabama                   8.0             222.0  \n",
              "           Alabama                   1.0               3.0  \n",
              "           Alabama                   0.0              20.0  \n",
              "           Alabama                   0.0              52.0  \n",
              "...                                  ...               ...  \n",
              "31-12-2021 Minnesota                 0.0               0.0  \n",
              "           Minnesota                 0.0               0.0  \n",
              "           Minnesota                 0.0               0.0  \n",
              "           Minnesota                 0.0               0.0  \n",
              "           Minnesota                 0.0               0.0  \n",
              "\n",
              "[1045599 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7180134e-ffc0-413b-8ddd-c9795968bef1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Admin2</th>\n",
              "      <th>Confirmed</th>\n",
              "      <th>Deaths</th>\n",
              "      <th>Deaths_on_day</th>\n",
              "      <th>Confirmed_on_day</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th>Province/State</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">01-01-2021</th>\n",
              "      <th>Alabama</th>\n",
              "      <td>Autauga</td>\n",
              "      <td>4239</td>\n",
              "      <td>50</td>\n",
              "      <td>2.0</td>\n",
              "      <td>49.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alabama</th>\n",
              "      <td>Baldwin</td>\n",
              "      <td>13823</td>\n",
              "      <td>169</td>\n",
              "      <td>8.0</td>\n",
              "      <td>222.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alabama</th>\n",
              "      <td>Barbour</td>\n",
              "      <td>1517</td>\n",
              "      <td>33</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alabama</th>\n",
              "      <td>Bibb</td>\n",
              "      <td>1854</td>\n",
              "      <td>46</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alabama</th>\n",
              "      <td>Blount</td>\n",
              "      <td>4693</td>\n",
              "      <td>63</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">31-12-2021</th>\n",
              "      <th>Minnesota</th>\n",
              "      <td>Koochiching</td>\n",
              "      <td>1996</td>\n",
              "      <td>29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Minnesota</th>\n",
              "      <td>Lac qui Parle</td>\n",
              "      <td>1341</td>\n",
              "      <td>26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Minnesota</th>\n",
              "      <td>Lake</td>\n",
              "      <td>1475</td>\n",
              "      <td>26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Minnesota</th>\n",
              "      <td>Lake of the Woods</td>\n",
              "      <td>566</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Minnesota</th>\n",
              "      <td>Le Sueur</td>\n",
              "      <td>5074</td>\n",
              "      <td>41</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1045599 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7180134e-ffc0-413b-8ddd-c9795968bef1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7180134e-ffc0-413b-8ddd-c9795968bef1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7180134e-ffc0-413b-8ddd-c9795968bef1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# making data frame from csv file\n",
        "data = pd.read_csv(\"us_simplified.csv\")\n",
        "\n",
        "data.drop('Country/Region', inplace=True, axis=1)\n",
        "\n",
        "# sorting data frame by multiple columns\n",
        "data.sort_values([\"Date\", \"Admin2\" , \"Province/State\" ], axis=0,\n",
        "\t\t\t\tascending=[True, True, True], inplace=True)\n",
        "\n",
        "# display\n",
        "print(data.head(100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV1b_BUUGaJY",
        "outputId": "abd8129c-5beb-4344-a50f-c1f109df1b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Date      Admin2 Province/State  Confirmed  Deaths\n",
            "859665   01-01-2021      Acadia      Louisiana       5082     153\n",
            "432609   01-01-2021         Ada          Idaho      38262     355\n",
            "614145   01-01-2021       Adair           Iowa        610      17\n",
            "768897   01-01-2021       Adair       Kentucky       1202      39\n",
            "191553   01-01-2021       Adams       Colorado      40304     521\n",
            "...             ...         ...            ...        ...     ...\n",
            "864129   01-01-2021   Bienville      Louisiana       1202      47\n",
            "1022601  01-01-2021   Big Stone      Minnesota        434       3\n",
            "436329   01-01-2021     Bingham          Idaho       3649      46\n",
            "618609   01-01-2021  Black Hawk           Iowa      12820     218\n",
            "547185   01-01-2021   Blackford        Indiana        895      24\n",
            "\n",
            "[100 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cod_mean ="
      ],
      "metadata": {
        "id": "5KZAdrG5nvFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing library\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "import math\n",
        "#reading the dataset\n",
        "cp = pd.read_csv('usa_final.csv')\n",
        "#taking the subset of the data\n",
        "# cp=cp[['symboling','wheelbase','carlength','carwidth','carheight','curbweight','boreratio','stroke','compressionratio','horsepower','peakrpm','citympg','highwaympg','price']]\n",
        "#printing first five rows of the data\n",
        "# cp.head()\n",
        "cp.skew()\n",
        "# sns.kdeplot(cp.Confirmed_on_day);\n",
        "# stats.probplot(cp.Confirmed_on_day,plot=pylab);\n",
        "def normality(usa_final,Confirmed_on_day):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    sns.kdeplot(usa_final[Confirmed_on_day])\n",
        "    plt.subplot(1,2,2)\n",
        "    stats.probplot(usa_final[Confirmed_on_day],plot=pylab)\n",
        "    # plt.show()\n",
        "# stats.probplot(cp.Confirmed_on_day,plot=pylab);\n",
        "# cp['Confirmed_on_day_log']=np.log(cp['Confirmed_on_day'])\n",
        "# normality(cp,'Confirmed_on_day_log')\n",
        "# cp['Confirmed_on_day_reciprocal']=1/cp.Confirmed_on_day\n",
        "# normality(cp,'Confirmed_on_day_reciprocal')\n",
        "cp['Confirmed_on_day_sqroot']=np.sqrt(cp.Confirmed_on_day)\n",
        "cp['Deaths_on_day_sqroot']=np.sqrt(cp.Deaths_on_day)\n",
        "print('Confirmed_on_day_sqroot')\n",
        "# normality(cp,'Confirmed_on_day_sqroot')\n",
        "# cp['cod_us_new']=np.sqrt(cp.Confirmed_on_day)\n",
        "# cod = cp['cod_us_new']\n",
        "cp['Confirmed_on_day_sqroot'].mean()\n",
        "cp['Deaths_on_day_sqroot'].mean()\n",
        "\n",
        "\n",
        "# cp['Confirmed_on_day_exponential']=cp.Confirmed_on_day**(1/1.2)\n",
        "# normality(cp,'Confirmed_on_day_exponential')\n",
        "# cp['Confirmed_on_day_Boxcox'],parameters=stats.boxcox(cp['Confirmed_on_day'])\n",
        "# normality(cp,'Deaths_on_day_Boxcox')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8feff8bf-97de-4d05-8e09-97e08b8fc216",
        "id": "e39-lNTFoBHA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confirmed_on_day_sqroot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32.8687273034253"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cod_mean = cp['Confirmed_on_day_sqroot'].mean()\n",
        "print(cod_mean)\n",
        "cod_sd = np.std(cp['Confirmed_on_day_sqroot'])\n",
        "print(cod_sd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oFVwSS9oC9t",
        "outputId": "f64afeb6-d256-4eff-838d-77fe84399f63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "277.1503705282212\n",
            "185.21160542130264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testmean = cp['Confirmed_on_day_sqroot']sample(n = 70)\n",
        "print(testmean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "fMpgcfv4SN4k",
        "outputId": "fecb2aa8-82a7-4da1-e8a6-c96a16df4ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-7a380c31127b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    testmean = cp['Confirmed_on_day_sqroot']sample(n = 70)\u001b[0m\n\u001b[0m                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypMean = 295\n",
        "N=745"
      ],
      "metadata": {
        "id": "kA6ivZyJo1jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Z test for cod_sqrt\n"
      ],
      "metadata": {
        "id": "jtXtslqopIDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = (cod_mean-295)/(cod_sd/math.sqrt(745))\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idZGDWb9pMqm",
        "outputId": "61d6542a-2a2a-4536-e7ab-c8e99d5ff3ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-2.6305050837541057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "T test on cod_sqrt"
      ],
      "metadata": {
        "id": "Eu59BojB0Ce0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as st\n",
        "st.ttest_1samp(cp['Confirmed_on_day_sqroot'],295)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2mvJXqGxjG8",
        "outputId": "03a7e465-34d5-4b60-bf5d-394ee49571da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_1sampResult(statistic=-2.6269718315431967, pvalue=0.00879242321089452)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Z test on dod_sqrt"
      ],
      "metadata": {
        "id": "_4hAN5470-mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dod_mean = cp['Deaths_on_day_sqroot'].mean()\n",
        "print(dod_mean)\n",
        "dod_sd = np.std(cp['Deaths_on_day_sqroot'])\n",
        "print(dod_sd)\n",
        "hypMean = 34.5\n",
        "N=745\n",
        "z = (dod_mean-34.5)/(dod_sd/math.sqrt(745))\n",
        "print(z)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWYLNdH2v2N8",
        "outputId": "e1de6490-3fab-4e39-a347-6bae89a4af65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32.8687273034253\n",
            "17.499047343389265\n",
            "-2.5444287697984618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "T test on dod_sqrt"
      ],
      "metadata": {
        "id": "L-EGplyN1EYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Z test on confirmed cases on day"
      ],
      "metadata": {
        "id": "BjvP396wi_AZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as st\n",
        "st.ttest_1samp(cp['Deaths_on_day_sqroot'],34.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyTtODFo1Hdk",
        "outputId": "b6f76825-e650-43dd-cae8-649dd16e5902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_1sampResult(statistic=-2.5410111339109434, pvalue=0.011255516707951808)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean1 = cp[['Confirmed_on_day']].iloc[[11,39]].mean(axis=0)\n",
        "print(mean1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rJ-ZnPJZgGv",
        "outputId": "dc7bf060-e92c-4c9f-8f0c-45064c1e8fd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confirmed_on_day    6.5\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "standard_deviation1= cp[['Confirmed_on_day']].iloc[[11,39]].std(axis=0)\n",
        "print(standard_deviation1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zIGNWS6ao4t",
        "outputId": "8a0b1aea-70e3-41ac-a1f8-777001e98f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confirmed_on_day    9.192388\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean2 = cp[['Confirmed_on_day']].iloc[[40,70]].mean(axis=0)\n",
        "print(mean2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWThhktwavF_",
        "outputId": "2099c19d-4f47-4799-a851-96d3004a300d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confirmed_on_day    17099.5\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "standard_deviation2= cp[['Confirmed_on_day']].iloc[[40,70]].std(axis=0)\n",
        "print(standard_deviation2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnantrhJbKkv",
        "outputId": "4c2b0de4-9978-404d-f064-43afd673a2c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confirmed_on_day    24154.060539\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "num_z = 17099.5-6.5-0\n",
        "a = ((standard_deviation1*standard_deviation1)/29)+ ((standard_deviation2*standard_deviation2)/31)\n",
        "den_z = math.sqrt(a)\n",
        "z = num_z/den_z\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9MccwCabriC",
        "outputId": "16e851d7-664e-4b0c-d8a9-8c2979bb5d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.940115523625636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMGm7B8geh63",
        "outputId": "22e06fe2-d4d2-4edb-9f10-a7ec73128a7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4338.197674029434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycc-vLp3izz5",
        "outputId": "1bd82992-344d-4876-ffcf-329c664890f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.940115523625636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothesis for deaths"
      ],
      "metadata": {
        "id": "y_6x_1JQjLjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "death_mean1=cp[['Deaths_on_day']].iloc[[40,70]].mean(axis=0)\n",
        "print(death_mean1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUo2OQR9lfM_",
        "outputId": "371052eb-fafd-420f-8c1e-40b19013f43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Deaths_on_day    879.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "death_standard_deviation1= cp[['Deaths_on_day']].iloc[[40,70]].std(axis=0)\n",
        "print(death_standard_deviation1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwi0xJsRmDXm",
        "outputId": "b9da2f7c-88f5-48f8-cb60-4243ea7f5571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deaths_on_day    1236.022654\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "death_mean2 = cp[['Deaths_on_day']].iloc[[71,100]].mean(axis=0)\n",
        "print(death_mean2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu90weeNmblb",
        "outputId": "ee2cdb61-7835-46ae-bc3f-61f4741297bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deaths_on_day    1889.0\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "death_standard_deviation2= cp[['Deaths_on_day']].iloc[[71,100]].std(axis=0)\n",
        "print(death_standard_deviation2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJg9-Rd0m7Uu",
        "outputId": "cf5ff99f-b851-4923-afc1-668fe298a9e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deaths_on_day    381.837662\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "death_num_z = 1889-879-0\n",
        "print(death_num_z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJNCyehenFLR",
        "outputId": "6b2a98b9-5db7-479b-9db6-a481fa4838c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = ((death_standard_deviation1*death_standard_deviation1)/31)+ ((death_standard_deviation2*death_standard_deviation2)/30)\n",
        "death_den_z = math.sqrt(b)\n",
        "print(death_den_z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ00rLCVnY7c",
        "outputId": "fb63a823-e562-4f49-b72a-4933649adf3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "232.68502869898003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "death_z = death_num_z/death_den_z\n",
        "print(death_z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drgmE8Ojnxl-",
        "outputId": "1027dc07-a66c-43e2-c7bc-12037724aff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.340631649776732\n"
          ]
        }
      ]
    }
  ]
}